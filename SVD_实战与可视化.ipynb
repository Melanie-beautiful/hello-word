{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Melanie-beautiful/hello-word/blob/master/SVD_%E5%AE%9E%E6%88%98%E4%B8%8E%E5%8F%AF%E8%A7%86%E5%8C%96.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def print_matrix(name, matrix):\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    # 为了显示美观，保留两位小数\n",
        "    print(np.round(matrix, 2))\n",
        "\n",
        "def step_by_step_svd_demo():\n",
        "    print(\"=\"*60)\n",
        "    print(\"第一部分：手动计算 SVD (Step-by-Step)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. 定义一个简单的矩阵 A\n",
        "    A = np.array([\n",
        "        [3, 1],\n",
        "        [1, 3]\n",
        "    ])\n",
        "    print_matrix(\"原始矩阵 A\", A)\n",
        "\n",
        "    # 2. 计算 A^T * A\n",
        "    # 我们用它来找 V (右奇异向量) 和 Sigma (奇异值)\n",
        "    ATA = np.dot(A.T, A)\n",
        "    print_matrix(\"A^T * A\", ATA)\n",
        "\n",
        "    # 3. 计算 ATA 的特征值和特征向量\n",
        "    eigenvalues, eigenvectors = np.linalg.eig(ATA)\n",
        "\n",
        "    # 排序：SVD要求奇异值从大到小排列\n",
        "    # argsort 返回的是从小到大的索引，所以我们需要反转\n",
        "    idx = eigenvalues.argsort()[::-1]\n",
        "    eigenvalues = eigenvalues[idx]\n",
        "    V = eigenvectors[:, idx]\n",
        "\n",
        "    print(\"\\n[计算中] ATA 的特征值 (lambda):\", np.round(eigenvalues, 2))\n",
        "\n",
        "    # 4. 计算奇异值 Sigma\n",
        "    # 奇异值是特征值的平方根\n",
        "    singular_values = np.sqrt(eigenvalues)\n",
        "    Sigma = np.diag(singular_values)\n",
        "\n",
        "    print_matrix(\"奇异值矩阵 Sigma\", Sigma)\n",
        "    print_matrix(\"右奇异向量矩阵 V\", V)\n",
        "\n",
        "    # 5. 计算 U (左奇异向量)\n",
        "    # 我们可以通过公式 u_i = (1/sigma_i) * A * v_i 来计算\n",
        "    # 这里直接使用 numpy 的 broadcasting 计算\n",
        "    U = np.zeros_like(A, dtype=float)\n",
        "    for i in range(len(singular_values)):\n",
        "        U[:, i] = np.dot(A, V[:, i]) / singular_values[i]\n",
        "\n",
        "    print_matrix(\"左奇异向量矩阵 U\", U)\n",
        "\n",
        "    # 6. 验证结果\n",
        "    print(\"\\n[验证] 让我们尝试把 U * Sigma * V.T 乘回去...\")\n",
        "    reconstructed_A = U @ Sigma @ V.T\n",
        "    print_matrix(\"重构后的 A (应与原始 A 相同)\", reconstructed_A)\n",
        "\n",
        "    if np.allclose(A, reconstructed_A):\n",
        "        print(\"\\nSUCCESS! 手动计算成功匹配。\")\n",
        "    else:\n",
        "        print(\"\\nNote: 符号可能与 numpy 标准库有差异，但数学性质一致。\")\n",
        "\n",
        "def svd_image_compression_demo():\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"第二部分：SVD 应用演示 - 图像压缩\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"正在生成示例图像并计算 SVD...\")\n",
        "\n",
        "    # 1. 创建一个合成图像 (简单的梯度 + 圆形)\n",
        "    # 这是一个 100x100 的矩阵\n",
        "    h, w = 200, 200\n",
        "    y, x = np.ogrid[:h, :w]\n",
        "    # 背景是一个对角线梯度\n",
        "    img = (x + y) * 0.5\n",
        "    # 添加一个圆形在中间\n",
        "    mask = (x - w/2)**2 + (y - h/2)**2 < (h/4)**2\n",
        "    img[mask] = 200\n",
        "\n",
        "    # 添加一些随机噪点\n",
        "    noise = np.random.randint(0, 50, (h, w))\n",
        "    img = img + noise\n",
        "\n",
        "    # 2. 使用 Numpy 的标准 SVD 函数进行分解\n",
        "    # full_matrices=False 表示这是经济型 SVD，只计算必要的部分\n",
        "    U, S, Vt = np.linalg.svd(img, full_matrices=False)\n",
        "\n",
        "    print(f\"原始图像大小: {img.shape}\")\n",
        "    print(f\"分解得到的奇异值数量: {len(S)}\")\n",
        "    print(\"奇异值前10个:\", np.round(S[:10], 1))\n",
        "\n",
        "    # 3. 可视化：使用不同数量的奇异值进行重构\n",
        "    # k 是“秩”，即我们要保留多少个奇异值\n",
        "    k_values = [5, 20, 50, 200]\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # 显示原图\n",
        "    plt.subplot(2, 3, 1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(\"Original Image\\n(Rank 200)\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # 绘制奇异值分布曲线 (Scree Plot)\n",
        "    plt.subplot(2, 3, 2)\n",
        "    plt.plot(S)\n",
        "    plt.title(\"Singular Values (Importance)\")\n",
        "    plt.xlabel(\"Index\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    # 循环展示不同压缩率的重构结果\n",
        "    for i, k in enumerate(k_values):\n",
        "        # 核心逻辑：低秩近似\n",
        "        # 只取前 k 列的 U，前 k 个 S，前 k 行的 Vt\n",
        "        # 相当于 A_approx = U[:, :k] * Sigma[:k, :k] * Vt[:k, :]\n",
        "\n",
        "        reconstructed_img = np.matrix(U[:, :k]) * np.diag(S[:k]) * np.matrix(Vt[:k, :])\n",
        "\n",
        "        plt.subplot(2, 3, i + 3) # 从第3个位置开始画\n",
        "        plt.imshow(reconstructed_img, cmap='gray')\n",
        "        compression_ratio = 100 * k / len(S)\n",
        "        plt.title(f\"Rank k={k}\\n(Used {compression_ratio:.0f}% of data)\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"绘图完成！请查看弹出的窗口。\")\n",
        "    print(\"观察：你可以看到 k=20 (仅10%的数据) 时，已经能看清图像的主要轮廓了。\")\n",
        "    print(\"这就是 SVD 能够提取'主要特征'的直观证明。\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    step_by_step_svd_demo()\n",
        "    svd_image_compression_demo()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "zpshH0Bn2SF-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}